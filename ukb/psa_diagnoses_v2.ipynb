{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.12.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "code", "source": "%%bash\ndx download \"UKB Metabolomics:/agarham/icd_med_dataset.tsv\"", "metadata": {"trusted": true, "tags": []}, "execution_count": 1, "outputs": [], "id": "4bc78efe-e7c7-40af-9119-7405efba2c09"}, {"cell_type": "code", "source": "# Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport re\n\n# Import the datasets\ndf = pd.read_csv('icd_med_dataset.tsv', sep='\\t')", "metadata": {"trusted": true, "tags": []}, "execution_count": 2, "outputs": [], "id": "bd526e5a-fd08-4521-9a9b-7cfeb68d81c7"}, {"cell_type": "code", "source": "# Create list of date columns\ndate_cols = [column for column in df.columns if column.startswith('41280-0.')]\n\n# Split the string by \"|\" and expand into separate columns\nsplit_cols = df['41270-0.0'].str.split('|', expand=True)\n\n# Rename columns to '41270-0.0', '41270-0.1', etc.\nsplit_cols.columns = [f'41270-0.{i}' for i in range(split_cols.shape[1])]\n\n# Return the splitted data to the original dataset\ndf[split_cols.columns] = split_cols", "metadata": {"trusted": true, "tags": []}, "execution_count": 3, "outputs": [], "id": "d495a410-ad18-4b80-a832-df400a59b50a"}, {"cell_type": "code", "source": "# Define the PsA codes\ncodes = [\n    'L405',\n    'M070', 'M0700', 'M0701', 'M0702', 'M0703', 'M0704', 'M0705', 'M0706', 'M0707', 'M0708', 'M0709',\n    'M071', 'M0710', 'M0711', 'M0712', 'M0713', 'M0714', 'M0715', 'M0716', 'M0717', 'M0718', 'M0719',\n    'M072', 'M0720', 'M0721', 'M0722', 'M0723', 'M0724', 'M0725', 'M0726', 'M0727', 'M0728', 'M0729',\n    'M073', 'M0730', 'M0731', 'M0732', 'M0733', 'M0734', 'M0735', 'M0736', 'M0737', 'M0738', 'M0739'\n]\n\n\n# Get all 41270 and 41280 columns\ncols_41270 = [col for col in df.columns if col.startswith('41270-0.')]\ncols_41280 = [col for col in df.columns if col.startswith('41280-0.')]\n\n# Initialize new columns\nfor code in codes:\n    df[code] = 0\n    df[f'{code}_date'] = np.nan\n\n# Iterate over rows\nfor idx, row in df.iterrows():\n    for col_41270 in cols_41270:\n        value = row[col_41270]\n        if value in codes:\n            # Mark code presence\n            df.at[idx, value] = 1\n\n            # Get corresponding date column\n            suffix = col_41270.split('41270-0.')[-1]\n            corresponding_col_41280 = f'41280-0.{suffix}'\n            \n            if corresponding_col_41280 in df.columns:\n                df.at[idx, f'{value}_date'] = row[corresponding_col_41280]", "metadata": {"trusted": true, "tags": []}, "execution_count": 4, "outputs": [], "id": "d494da4d-1aef-4219-a4ad-f29bea8a7293"}, {"cell_type": "code", "source": "# Convert date columns to datetime\ndate_cols = [f'{code}_date' for code in codes]\n\nfor col in date_cols:\n    df[col] = pd.to_datetime(df[col], errors='coerce')\n\n# Create a boolean df where code columns == 1\ncode_bool = df[codes] == 1\n\n# psa = 1 if any code column is 1, else 0\ndf['psa'] = code_bool.any(axis=1).astype(int)\n\n# Create a mask to keep dates only where corresponding code == 1, else NaT\nmasked_dates = df[date_cols].where(code_bool.values)\n\n# psa_date = earliest date (min) among the masked dates per row\ndf['psa_date'] = masked_dates.min(axis=1)", "metadata": {"trusted": true, "tags": []}, "execution_count": 6, "outputs": [], "id": "d8843d94-848e-49ac-8fc7-b63fde39b02b"}, {"cell_type": "code", "source": "# Check the number of PsA diagnoses\nprint(df['psa'].value_counts())\nprint(df['psa_date'].count())", "metadata": {"trusted": true, "tags": []}, "execution_count": 7, "outputs": [{"name": "stdout", "text": "0    500351\n1      1615\nName: psa, dtype: int64\n1615\n", "output_type": "stream"}], "id": "68592f33-f944-4132-8204-147cf148cb9c"}, {"cell_type": "code", "source": "# Check how many rows have value 0 in L405 column, while any of the other columns contains 1 in that row.\ntarget_col = 'L405'\n\n# Condition 1: target_col == 0\ncond_target_0 = df[target_col] == 0\n\n# Condition 2: all other codes == 1\nother_cols = [col for col in codes if col != target_col]\ncond_others_1 = (df[other_cols] == 1).any(axis=1)\n\n# Rows where target_col is 0 and any others are 1\nresult_rows = df[cond_target_0 & cond_others_1]\n\n# Count them\ncount = result_rows.shape[0]\n\nprint(f\"Number of rows where '{target_col}' is 0 but others have at least one 1: {count}\")", "metadata": {"trusted": true, "tags": []}, "execution_count": 8, "outputs": [{"name": "stdout", "text": "Number of rows where 'L405' is 0 but others have at least one 1: 6\n", "output_type": "stream"}], "id": "732cc96b-859c-48da-b280-8fab364182db"}, {"cell_type": "code", "source": "# Select columns starting with 'M07'\nm07_cols = [code for code in codes if code.startswith('M07')]\n\n# Count how many 'M07' columns are 1 per row\ncount_ones = (df[m07_cols] == 1).sum(axis=1)\n\n# Filter rows with two or more 1s in 'M07' columns\nrows_multiple_ones = df[count_ones >= 2]\n\n# Number of such rows\ncount = rows_multiple_ones.shape[0]\n\nprint(f\"Number of rows with two or more 1s in columns starting with 'M07': {count}\")", "metadata": {"trusted": true, "tags": []}, "execution_count": 9, "outputs": [{"name": "stdout", "text": "Number of rows with two or more 1s in columns starting with 'M07': 492\n", "output_type": "stream"}], "id": "8ec65453-dd42-4199-99a1-00e73d12bbe2"}, {"cell_type": "code", "source": "# Check the number of PsA diagnoses\nprint(df['L405'].value_counts())\nprint(df['L405_date'].count())\nprint(df['M073'].value_counts())\nprint(df['M073_date'].count())\nprint(df['M0739'].value_counts())\nprint(df['M0739_date'].count())", "metadata": {"trusted": true, "tags": []}, "execution_count": 10, "outputs": [{"name": "stdout", "text": "0    500357\n1      1609\nName: L405, dtype: int64\n1609\n0    500719\n1      1247\nName: M073, dtype: int64\n1247\n0    501517\n1       449\nName: M0739, dtype: int64\n449\n", "output_type": "stream"}], "id": "667df696-540e-45cd-8950-047c20e560cc"}, {"cell_type": "code", "source": "# Slice and save the output\npsa = df[['eid', 'psa', 'psa_date']]\npsa.to_csv('psa_diagnoses_v2.tsv', sep='\\t', index=False)", "metadata": {"trusted": true, "tags": []}, "execution_count": 11, "outputs": [], "id": "d8a102f3-0f4b-4c4f-b001-8d44b4372f02"}, {"cell_type": "code", "source": "%%bash\ndx upload \"psa_diagnoses_v2.tsv\"", "metadata": {"tags": []}, "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "ID                                file-J1VxxX0JZ8jYFq1Y2Xb0861q\n\nClass                             file\n\nProject                           project-J0yb91QJZ8jZ9ppFk6zGQgGp\n\nFolder                            /\n\nName                              psa_diagnoses.tsv\n\nState                             closing\n\nVisibility                        visible\n\nTypes                             -\n\nProperties                        -\n\nTags                              -\n\nOutgoing links                    -\n\nCreated                           Tue Jul  1 13:12:40 2025\n\nCreated by                        agarham\n\n via the job                      job-J1Vvz08JZ8jkFzKbfV8fJVQV\n\nLast modified                     Tue Jul  1 13:12:41 2025\n\nMedia type                        \n\narchivalState                     \"live\"\n\ncloudAccount                      \"cloudaccount-dnanexus\"\n"}], "id": "4f35eee7-8ee0-41d7-9797-7f1b0434543a"}]}